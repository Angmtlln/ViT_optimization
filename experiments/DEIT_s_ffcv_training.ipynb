{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T17:41:53.137866Z",
     "start_time": "2025-07-30T17:41:49.799881Z"
    }
   },
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import RGBImageField, IntField\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class CIFAR10Adapter:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        img = np.array(img)  # Преобразуем PIL → numpy (H, W, 3)\n",
    "        return img, label\n",
    "\n",
    "# Путь для сохранения\n",
    "write_path = './data/cifar10_train.beton'\n",
    "\n",
    "# Загружаем CIFAR-10\n",
    "cifar_train = CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "# Оборачиваем\n",
    "dataset = CIFAR10Adapter(cifar_train)\n",
    "\n",
    "# Создание writer-а\n",
    "writer = DatasetWriter(write_path, {\n",
    "    'image': RGBImageField(write_mode='smart', max_resolution=32),\n",
    "    'label': IntField()\n",
    "})\n",
    "\n",
    "# Пишем данные\n",
    "writer.from_indexed_dataset(dataset)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:00<00:00, 83099.26it/s] \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T17:40:15.872427Z",
     "start_time": "2025-07-30T17:40:15.355004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = timm.create_model('deit_small_patch16_224', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 10)\n",
    "model = model.to(device)"
   ],
   "id": "357da6e19cda1787",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T17:40:16.532214Z",
     "start_time": "2025-07-30T17:40:16.529112Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "id": "7d166a64af5ad8f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T17:41:54.755174Z",
     "start_time": "2025-07-30T17:41:54.738820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ffcv.reader import Reader\n",
    "\n",
    "reader = Reader('./data/cifar10_train.beton')\n",
    "print(reader.metadata)  # Список полей и форматы"
   ],
   "id": "a81a6ac8368898ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 32, 32,   8388608), 6) ((1, 32, 32,   8391680), 9)\n",
      " ((1, 32, 32,   8394752), 9) ... ((1, 32, 32, 108948480), 9)\n",
      " ((1, 32, 32, 108951552), 1) ((1, 32, 32, 108954624), 1)]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T17:36:54.142800Z",
     "start_time": "2025-07-30T17:36:54.136870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ffcv.transforms import RandomResizedCrop, RandomHorizontalFlip\n",
    "from ffcv.transforms import ToTensor, ToDevice, ToTorchImage, Convert\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToTensor, ToDevice, ToTorchImage, Cutout, NormalizeImage\n",
    "from ffcv.fields.decoders import IntDecoder, RandomResizedCropRGBImageDecoder\n",
    "from torch import float32\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_pipeline = [\n",
    "    #RandomResizedCropRGBImageDecoder((224, 224)),\n",
    "    SimpleRGBImageDecoder(),\n",
    "    ToTensor(),\n",
    "    ToTorchImage(),\n",
    "    NormalizeImage(\n",
    "        mean=np.array([0.4914, 0.4822, 0.4465], dtype=np.float32),\n",
    "        std=np.array([0.2023, 0.1994, 0.2010], dtype=np.float32),\n",
    "        type=np.float32\n",
    "    )\n",
    "]\n",
    "\n",
    "label_pipeline = [\n",
    "    IntDecoder(),\n",
    "    ToTensor()\n",
    "]"
   ],
   "id": "de190591fd9285af",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T17:33:31.091864Z",
     "start_time": "2025-07-30T17:33:31.089564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "shutil.rmtree('/home/amir_ubuntu/.cache/ffcv/loader_cache', ignore_errors=True)"
   ],
   "id": "927eb9c52b44e4dd",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T17:39:24.833450Z",
     "start_time": "2025-07-30T17:36:57.342854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = Loader(\n",
    "    './data/cifar10_train.beton',\n",
    "    batch_size=32,\n",
    "    num_workers=0,\n",
    "    order=OrderOption.RANDOM,\n",
    "    drop_last=True,\n",
    "    os_cache=True,\n",
    "    recompile=False,\n",
    "    pipelines={\n",
    "        'image': image_pipeline,\n",
    "        'label': label_pipeline\n",
    "    }\n",
    ")\n"
   ],
   "id": "57b49d80dabace63",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m train_loader = \u001B[43mLoader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m./data/cifar10_train.beton\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43mOrderOption\u001B[49m\u001B[43m.\u001B[49m\u001B[43mRANDOM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdrop_last\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mos_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrecompile\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpipelines\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mimage\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage_pipeline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlabel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_pipeline\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/loader/loader.py:210\u001B[39m, in \u001B[36mLoader.__init__\u001B[39m\u001B[34m(self, fname, batch_size, num_workers, os_cache, order, distributed, seed, indices, pipelines, custom_fields, drop_last, batches_ahead, recompile)\u001B[39m\n\u001B[32m    204\u001B[39m         \u001B[38;5;28mself\u001B[39m.pipeline_specs[field_name] = spec\n\u001B[32m    206\u001B[39m \u001B[38;5;28mself\u001B[39m.graph = Graph(\u001B[38;5;28mself\u001B[39m.pipeline_specs, \u001B[38;5;28mself\u001B[39m.reader.handlers,\n\u001B[32m    207\u001B[39m                    \u001B[38;5;28mself\u001B[39m.field_name_to_f_ix, \u001B[38;5;28mself\u001B[39m.reader.metadata,\n\u001B[32m    208\u001B[39m                    memory_read)\n\u001B[32m--> \u001B[39m\u001B[32m210\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_code\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[38;5;28mself\u001B[39m.first_traversal_order = \u001B[38;5;28mself\u001B[39m.next_traversal_order()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/loader/loader.py:276\u001B[39m, in \u001B[36mLoader.generate_code\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    274\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_code\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    275\u001B[39m     queries, code = \u001B[38;5;28mself\u001B[39m.graph.collect_requirements()\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m     \u001B[38;5;28mself\u001B[39m.code = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcodegen_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/pipeline/graph.py:476\u001B[39m, in \u001B[36mGraph.codegen_all\u001B[39m\u001B[34m(self, code)\u001B[39m\n\u001B[32m    475\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcodegen_all\u001B[39m(\u001B[38;5;28mself\u001B[39m, code):\n\u001B[32m--> \u001B[39m\u001B[32m476\u001B[39m     stages = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroup_operations\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    477\u001B[39m     code_stages = []\n\u001B[32m    478\u001B[39m     already_defined = []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/pipeline/graph.py:392\u001B[39m, in \u001B[36mGraph.group_operations\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    389\u001B[39m jitted_stage = \u001B[38;5;28mlen\u001B[39m(stages) % \u001B[32m2\u001B[39m == \u001B[32m0\u001B[39m\n\u001B[32m    391\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m current_front:\n\u001B[32m--> \u001B[39m\u001B[32m392\u001B[39m     node = \u001B[43mcurrent_front\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    393\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m node.is_jitted == jitted_stage \u001B[38;5;129;01mor\u001B[39;00m node.is_jitted \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    394\u001B[39m         current_stage.append(\u001B[38;5;28mself\u001B[39m.node_to_id[node])\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:31:03.812890Z",
     "start_time": "2025-07-30T10:20:48.018377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.squeeze(1)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, pred = output.max(1)\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Train loss: {total_loss:.3f}, Accuracy: {acc:.2f}%\")\n"
   ],
   "id": "2ba81d12a0b69a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/390 [00:00<?, ?it/s]Exception ignored in: <finalize object at 0x733165fd5ee0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/weakref.py\", line 590, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amir_ubuntu/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/numba/core/dispatcher.py\", line 268, in finalizer\n",
      "    for cres in overloads.values():\n",
      "KeyError: (Array(uint8, 1, 'C', True, aligned=True), Array(uint8, 1, 'C', True, aligned=True), uint32, uint32, uint32, uint32, Literal[int](0), Literal[int](0), Literal[int](1), Literal[int](1), Literal[bool](False), Literal[bool](False))\n",
      "Exception ignored in: <finalize object at 0x733165c39080; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/weakref.py\", line 590, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amir_ubuntu/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/numba/core/dispatcher.py\", line 268, in finalizer\n",
      "    for cres in overloads.values():\n",
      "KeyError: (Array(uint8, 1, 'C', True, aligned=True), Array(uint8, 1, 'C', True, aligned=True))\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/amir_ubuntu/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/loader/epoch_iterator.py\", line 84, in run\n",
      "    result = self.run_pipeline(b_ix, ixes, slot, events[slot])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/amir_ubuntu/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/loader/epoch_iterator.py\", line 146, in run_pipeline\n",
      "    results = stage_code(**args)\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"\", line 2, in stage_code_0\n",
      "TypeError: not enough arguments: expected 4, got 2\n",
      "Epoch 1:   0%|          | 0/390 [10:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     11\u001B[39m correct = \u001B[32m0\u001B[39m\n\u001B[32m     12\u001B[39m total = \u001B[32m0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mEpoch \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepoch\u001B[49m\u001B[43m+\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m.\u001B[49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Убираем размерность 1, превращаем в [128]\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/ffcv/loader/epoch_iterator.py:155\u001B[39m, in \u001B[36mEpochIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m155\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moutput_queue\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    156\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    157\u001B[39m         \u001B[38;5;28mself\u001B[39m.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/queue.py:171\u001B[39m, in \u001B[36mQueue.get\u001B[39m\u001B[34m(self, block, timeout)\u001B[39m\n\u001B[32m    169\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    170\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._qsize():\n\u001B[32m--> \u001B[39m\u001B[32m171\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnot_empty\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m timeout < \u001B[32m0\u001B[39m:\n\u001B[32m    173\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[33mtimeout\u001B[39m\u001B[33m'\u001B[39m\u001B[33m must be a non-negative number\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/threading.py:355\u001B[39m, in \u001B[36mCondition.wait\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    353\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[32m    354\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m355\u001B[39m         \u001B[43mwaiter\u001B[49m\u001B[43m.\u001B[49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    356\u001B[39m         gotit = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    357\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:51:00.366146Z",
     "start_time": "2025-07-29T19:51:00.361659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "save_dir = '../data/model_weights'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ],
   "id": "1521b5d302dd7a6d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:51:10.641273Z",
     "start_time": "2025-07-29T19:51:09.696135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = os.path.join(save_dir, 'deit_small_cifar10.pth')\n",
    "try:\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'accuracy': acc,\n",
    "    }, model_path)\n",
    "    print(f\"Модель сохранена в {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении модели: {e}\")\n"
   ],
   "id": "6cf913232ff82fc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в data/model_weights/deit_small_cifar10.pth\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "677a81e04ae2529c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
