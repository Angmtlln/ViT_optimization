{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-29T14:15:19.223208Z",
     "start_time": "2025-07-29T14:15:10.977842Z"
    }
   },
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from ffcv.writer import DatasetWriter\n",
    "from ffcv.fields import RGBImageField, IntField\n",
    "from torch.utils.data import Subset\n",
    "import os\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToTensor, ToDevice, ToTorchImage, Convert\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "write_path = '/tmp/cifar10_train.beton'\n",
    "\n",
    "\n",
    "cifar_train = CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "\n",
    "dataset = Subset(cifar_train, range(len(cifar_train)))\n",
    "\n",
    "\n",
    "writer = DatasetWriter(write_path, {\n",
    "    'image': RGBImageField(max_resolution=32),\n",
    "    'label': IntField()\n",
    "})\n",
    "\n",
    "\n",
    "writer.from_indexed_dataset(dataset)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amir_ubuntu/.virtualenvs/transformer-model-optimization/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 98201.32it/s] \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T14:36:14.779647Z",
     "start_time": "2025-07-29T14:36:13.653319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = timm.create_model('deit_small_patch16_224', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 10)\n",
    "model = model.to(device)"
   ],
   "id": "357da6e19cda1787",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T14:36:16.083569Z",
     "start_time": "2025-07-29T14:36:15.859074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ffcv.transforms import RandomResizedCrop, RandomHorizontalFlip\n",
    "from ffcv.transforms import ToTensor, ToDevice, ToTorchImage, Convert\n",
    "from ffcv.fields.decoders import IntDecoder, SimpleRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.transforms import ToTensor, ToDevice, ToTorchImage, Cutout\n",
    "from ffcv.fields.decoders import IntDecoder, RandomResizedCropRGBImageDecoder\n",
    "from torch import float32\n",
    "\n",
    "\n",
    "image_pipeline = [\n",
    "    RandomResizedCropRGBImageDecoder((224, 224)),\n",
    "    Cutout(16),\n",
    "    ToTensor(),\n",
    "    ToTorchImage(),\n",
    "    Convert(float32),\n",
    "    ToDevice(device)\n",
    "]\n",
    "\n",
    "label_pipeline = [\n",
    "    IntDecoder(),\n",
    "    ToTensor(),\n",
    "    ToDevice(device)\n",
    "]\n",
    "\n",
    "train_loader = Loader(\n",
    "    './data/cifar10_train.beton',\n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    order=OrderOption.RANDOM,\n",
    "    drop_last=True,\n",
    "    pipelines={\n",
    "        'image': image_pipeline,\n",
    "        'label': label_pipeline\n",
    "    }\n",
    ")\n"
   ],
   "id": "57b49d80dabace63",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T14:59:36.263756Z",
     "start_time": "2025-07-29T14:36:20.205062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        optimizer.zero_grad()\n",
    "        labels = labels.squeeze(1)  # Убираем размерность 1, превращаем в [128]\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, pred = output.max(1)\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    acc = 100. * correct / total\n",
    "    print(f\"Train loss: {total_loss:.3f}, Accuracy: {acc:.2f}%\")\n"
   ],
   "id": "2ba81d12a0b69a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 390/390 [02:22<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 780.921, Accuracy: 24.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 390/390 [02:18<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 653.135, Accuracy: 38.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 390/390 [02:18<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 605.927, Accuracy: 43.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 390/390 [02:19<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 574.814, Accuracy: 46.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 390/390 [02:20<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 557.909, Accuracy: 48.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 390/390 [02:18<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 539.914, Accuracy: 50.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 390/390 [02:19<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 527.382, Accuracy: 51.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 390/390 [02:19<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 517.538, Accuracy: 52.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 390/390 [02:19<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 505.377, Accuracy: 53.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 390/390 [02:18<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 498.128, Accuracy: 54.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:51:00.366146Z",
     "start_time": "2025-07-29T19:51:00.361659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "save_dir = '../data/model_weights'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ],
   "id": "1521b5d302dd7a6d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T19:51:10.641273Z",
     "start_time": "2025-07-29T19:51:09.696135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = os.path.join(save_dir, 'deit_small_cifar10.pth')\n",
    "try:\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'accuracy': acc,\n",
    "    }, model_path)\n",
    "    print(f\"Модель сохранена в {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении модели: {e}\")\n"
   ],
   "id": "6cf913232ff82fc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в data/model_weights/deit_small_cifar10.pth\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "677a81e04ae2529c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
