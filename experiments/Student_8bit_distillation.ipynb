{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:01:29.521631Z",
     "start_time": "2025-08-06T19:01:27.755463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import timm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from EMA_for_weights import EMA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = torch.load(\"../data/cifar10_cutmix.pt\")\n",
    "images, labels = data\n",
    "\n",
    "num_classes = len(labels.unique()) if labels.ndim == 1 else labels.shape[1]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(images, labels),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "teacher_model = timm.create_model(\"deit_small_patch16_224\", pretrained=False, num_classes=10)\n",
    "teacher_model.load_state_dict(torch.load(\"../data/model_weights/deit_s_cifar10_aug.pt\"))\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()\n",
    "\n",
    "student_model = timm.create_model(\"deit_tiny_patch16_224\", pretrained=True, num_classes=10)\n",
    "student_model.to(device)\n",
    "\n",
    "student_model_quantized = torch.quantization.quantize_dynamic(\n",
    "    student_model,\n",
    "    {nn.Linear, nn.Conv2d},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=4.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    def forward(self, student_outputs, teacher_outputs, labels):\n",
    "        if labels.ndim > 1:\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "        labels = labels.long()\n",
    "        ce_loss = self.ce_loss(student_outputs, labels)\n",
    "\n",
    "        student_logits = student_outputs / self.temperature\n",
    "        teacher_logits = teacher_outputs / self.temperature\n",
    "        distill_loss = self.kl_loss(\n",
    "            F.log_softmax(student_logits, dim=1),\n",
    "            F.softmax(teacher_logits, dim=1)\n",
    "        ) * (self.temperature ** 2)\n",
    "\n",
    "        loss = (1 - self.alpha) * ce_loss + self.alpha * distill_loss\n",
    "        return loss"
   ],
   "id": "720c519a59de1d6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:11:24.265392Z",
     "start_time": "2025-08-06T19:01:31.889485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = DistillationLoss(alpha=0.7, temperature=4.0)\n",
    "optimizer = optim.AdamW(student_model.parameters(), lr=5e-5)\n",
    "ema = EMA(student_model, decay=0.999)\n",
    "\n",
    "epochs = 5\n",
    "student_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for x, y in loop:\n",
    "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        student_outputs = student_model(x)\n",
    "\n",
    "        loss = criterion(student_outputs, teacher_outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema.update(student_model)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = student_outputs.argmax(dim=1)\n",
    "        if y.ndim > 1:\n",
    "            y_true = torch.argmax(y, dim=1)\n",
    "        else:\n",
    "            y_true = y\n",
    "        correct = (preds == y_true).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "        loop.set_postfix(loss=loss.item(), accuracy=f\"{accuracy:.2f}%\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_accuracy = 100 * total_correct / total_samples\n",
    "    print(f\"[Epoch {epoch+1}] Avg Loss: {avg_loss:.4f}, Avg Accuracy: {avg_accuracy:.2f}%\")"
   ],
   "id": "a04176d904adefc3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 782/782 [01:56<00:00,  6.74it/s, accuracy=76.39%, loss=2.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Avg Loss: 2.1087, Avg Accuracy: 76.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 782/782 [02:00<00:00,  6.49it/s, accuracy=88.84%, loss=0.349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Avg Loss: 0.8599, Avg Accuracy: 88.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 782/782 [01:56<00:00,  6.70it/s, accuracy=92.36%, loss=0.403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Avg Loss: 0.5830, Avg Accuracy: 92.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 782/782 [01:56<00:00,  6.69it/s, accuracy=94.55%, loss=0.725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Avg Loss: 0.4367, Avg Accuracy: 94.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 782/782 [02:02<00:00,  6.39it/s, accuracy=96.03%, loss=0.295]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Avg Loss: 0.3454, Avg Accuracy: 96.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:11:30.999984Z",
     "start_time": "2025-08-06T19:11:30.413964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(student_model.state_dict(), \"../data/model_weights/deit_tiny_full_distilled.pt\")\n",
    "torch.save(ema.state_dict(), \"../data/model_weights/deit_tiny_full_distilled_ema.pt\")\n",
    "\n",
    "student_model.eval().cpu()  # Переводим в режим оценки и на CPU\n",
    "student_model_quantized = torch.quantization.quantize_dynamic(\n",
    "    student_model,\n",
    "    {nn.Linear, nn.Conv2d},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "torch.save(student_model_quantized.state_dict(), \"../data/model_weights/deit_tiny_8bit_distilled.pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.save(teacher_model.cpu().state_dict(), \"../data/model_weights/teacher_temp.pt\")\n",
    "    torch.save(student_model.state_dict(), \"../data/model_weights/student_full_temp.pt\")\n",
    "    torch.save(student_model_quantized.state_dict(), \"../data/model_weights/student_quant_temp.pt\")\n",
    "\n",
    "    teacher_size = os.path.getsize(\"../data/model_weights/teacher_temp.pt\") / (1024 * 1024)\n",
    "    student_full_size = os.path.getsize(\"../data/model_weights/student_full_temp.pt\") / (1024 * 1024)\n",
    "    student_quant_size = os.path.getsize(\"../data/model_weights/student_quant_temp.pt\") / (1024 * 1024)\n",
    "\n",
    "    print(f\"Размер модели учителя: {teacher_size:.2f} МБ\")\n",
    "    print(f\"Размер студента (полная точность): {student_full_size:.2f} МБ\")\n",
    "    print(f\"Размер квантизированной модели студента: {student_quant_size:.2f} МБ\")\n",
    "    print(f\"Сжатие: {teacher_size/student_quant_size:.2f}x\")\n"
   ],
   "id": "6d228760228ab38c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер модели учителя: 82.72 МБ\n",
      "Размер студента (полная точность): 21.14 МБ\n",
      "Размер квантизированной модели студента: 5.98 МБ\n",
      "Сжатие: 13.84x\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a6db67661dc3b3a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
