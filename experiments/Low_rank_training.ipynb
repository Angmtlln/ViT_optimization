{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-06T19:11:44.968466Z",
     "start_time": "2025-08-06T19:11:44.713783Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import timm\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "from experiments.EMA_for_weights import EMA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = torch.load(\"../data/cifar10_cutmix.pt\")\n",
    "images, labels = data\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(images, labels),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:11:46.268517Z",
     "start_time": "2025-08-06T19:11:45.792746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "teacher_model = timm.create_model(\"deit_small_patch16_224\", pretrained=False, num_classes=10)\n",
    "teacher_model.load_state_dict(torch.load(\"../data/model_weights/deit_s_cifar10_aug.pt\"))\n",
    "teacher_model.to(device)\n",
    "teacher_model.eval()\n",
    "\n",
    "class LowRankLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=None, bias=True):\n",
    "        super().__init__()\n",
    "        if rank is None:\n",
    "            rank = min(in_features, out_features) // 4\n",
    "        self.rank = rank\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.U = nn.Parameter(torch.Tensor(in_features, rank))\n",
    "        self.V = nn.Parameter(torch.Tensor(rank, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.U, a=np.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.V, a=np.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.U)\n",
    "            bound = 1 / np.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input @ self.U @ self.V\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def from_linear(linear_layer, rank=None):\n",
    "        W = linear_layer.weight.data.t()\n",
    "        in_f, out_f = W.shape\n",
    "        if rank is None:\n",
    "            rank = min(in_f, out_f) // 4\n",
    "        rank = min(rank, in_f, out_f)\n",
    "        low_rank = LowRankLinear(in_f, out_f, rank, bias=(linear_layer.bias is not None))\n",
    "        U_full, S, V_full = torch.svd(W)\n",
    "        low_rank.U.data = U_full[:, :rank] * S[:rank].unsqueeze(0)\n",
    "        low_rank.V.data = V_full.t()[:rank, :]\n",
    "        if linear_layer.bias is not None:\n",
    "            low_rank.bias.data = linear_layer.bias.data.clone()\n",
    "        return low_rank"
   ],
   "id": "85e08320b25eabbc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:11:48.010344Z",
     "start_time": "2025-08-06T19:11:46.866873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_low_rank_model(model, rank_factor=4):\n",
    "    new_model = copy.deepcopy(model)\n",
    "    skip = ['qkv', 'norm', 'cls_token', 'pos_embed']\n",
    "    replaced = skipped = 0\n",
    "    modules = dict(new_model.named_modules())\n",
    "    for name, module in modules.items():\n",
    "        if not isinstance(module, nn.Linear):\n",
    "            continue\n",
    "        if any(k in name for k in skip):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        rank = min(module.in_features, module.out_features) // rank_factor\n",
    "        if rank < 2:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        low_rank = LowRankLinear.from_linear(module, rank=rank)\n",
    "        # Встраиваем обратно\n",
    "        parent_name, attr = (name.rsplit('.', 1) + [''])[:2]\n",
    "        parent = modules[parent_name] if parent_name else new_model\n",
    "        setattr(parent, attr, low_rank)\n",
    "        replaced += 1\n",
    "    print(f\"Replaced {replaced} layers, skipped {skipped}\")\n",
    "    return new_model\n",
    "\n",
    "base_model = timm.create_model(\"deit_tiny_patch16_224\", pretrained=True, num_classes=10)\n",
    "student_model = create_low_rank_model(base_model, rank_factor=4)\n",
    "student_model.to(device)\n",
    "\n",
    "ema = EMA(student_model, decay=0.999)\n",
    "\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, temperature=4.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "        self.kl = nn.KLDivLoss(reduction='batchmean')\n",
    "    def forward(self, student_out, teacher_out, labels):\n",
    "        if labels.ndim > 1:\n",
    "            labels = labels.argmax(dim=1)\n",
    "        ce_loss = self.ce(student_out, labels)\n",
    "        s_logits = student_out / self.temperature\n",
    "        t_logits = teacher_out / self.temperature\n",
    "        distill = self.kl(F.log_softmax(s_logits,1), F.softmax(t_logits,1)) * (self.temperature**2)\n",
    "        return (1-self.alpha)*ce_loss + self.alpha*distill"
   ],
   "id": "d9cd0e45120dfccb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced 37 layers, skipped 12\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:21:03.381935Z",
     "start_time": "2025-08-06T19:11:49.967702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = DistillationLoss(alpha=0.7, temperature=4.0)\n",
    "optimizer = optim.AdamW(student_model.parameters(), lr=5e-5)\n",
    "epochs = 5\n",
    "\n",
    "student_model.train()\n",
    "for epoch in range(1, epochs+1):\n",
    "    total_loss = total_corr = total_samples = 0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "        x = F.interpolate(x, size=(224,224), mode='bilinear', align_corners=False).to(device)\n",
    "        y = y.to(device)\n",
    "        with torch.no_grad():\n",
    "            t_out = teacher_model(x)\n",
    "        optimizer.zero_grad()\n",
    "        s_out = student_model(x)\n",
    "        loss = criterion(s_out, t_out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ema.update(student_model)\n",
    "        total_loss += loss.item()\n",
    "        preds = s_out.argmax(dim=1)\n",
    "        true = y.argmax(1) if y.ndim>1 else y\n",
    "        total_corr += (preds == true).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "    print(f\"[Epoch {epoch}] Loss: {total_loss/len(train_loader):.4f}, Acc: {100*total_corr/total_samples:.2f}%\")"
   ],
   "id": "c22875b15e4a90b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 782/782 [01:50<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 5.0986, Acc: 42.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 782/782 [01:50<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Loss: 3.4735, Acc: 60.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 782/782 [01:50<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Loss: 2.7883, Acc: 67.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 782/782 [01:50<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Loss: 2.3646, Acc: 71.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 782/782 [01:50<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Loss: 2.0297, Acc: 75.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T19:21:03.640638Z",
     "start_time": "2025-08-06T19:21:03.444452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.save(student_model.state_dict(), \"../data/model_weights/deit_tiny_low_rank.pt\")\n",
    "torch.save(ema.state_dict(), \"../data/model_weights/deit_tiny_low_rank_ema.pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.save(teacher_model.cpu().state_dict(), \"../data/model_weights/teacher_temp.pt\")\n",
    "    torch.save(base_model.cpu().state_dict(), \"../data/model_weights/student_base_temp.pt\")\n",
    "    torch.save(student_model.cpu().state_dict(), \"../data/model_weights/student_low_rank_temp.pt\")\n",
    "\n",
    "    teacher_size = os.path.getsize(\"../data/model_weights/teacher_temp.pt\") / (1024 * 1024)\n",
    "    student_base_size = os.path.getsize(\"../data/model_weights/student_base_temp.pt\") / (1024 * 1024)\n",
    "    student_low_rank_size = os.path.getsize(\"../data/model_weights/student_low_rank_temp.pt\") / (1024 * 1024)\n",
    "\n",
    "    print(f\"Размер модели учителя: {teacher_size:.2f} МБ\")\n",
    "    print(f\"Размер базовой модели студента: {student_base_size:.2f} МБ\")\n",
    "    print(f\"Размер низкоранговой модели студента: {student_low_rank_size:.2f} МБ\")\n",
    "    print(f\"Сжатие относительно учителя: {teacher_size / student_low_rank_size:.2f}x\")\n",
    "    print(f\"Сжатие относительно базовой модели: {student_base_size / student_low_rank_size:.2f}x\")\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"Количество параметров в учителе: {count_parameters(teacher_model):,}\")\n",
    "print(f\"Количество параметров в базовом студенте: {count_parameters(base_model):,}\")\n",
    "print(f\"Количество параметров в низкоранговом студенте: {count_parameters(student_model):,}\")"
   ],
   "id": "e03baa612c2c48bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер модели учителя: 82.72 МБ\n",
      "Размер базовой модели студента: 21.14 МБ\n",
      "Размер низкоранговой модели студента: 11.03 МБ\n",
      "Сжатие относительно учителя: 7.50x\n",
      "Сжатие относительно базовой модели: 1.92x\n",
      "Количество параметров в учителе: 21,669,514\n",
      "Количество параметров в базовом студенте: 5,526,346\n",
      "Количество параметров в низкоранговом студенте: 2,872,552\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e9bafbc6138b4f20"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
